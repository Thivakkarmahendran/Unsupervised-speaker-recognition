{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import time\n",
    "import librosa\n",
    "import os\n",
    "from glob import glob\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Speaker', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n"
     ]
    }
   ],
   "source": [
    "#get speaker list\n",
    "\n",
    "speakers = [\"No Speaker\"]\n",
    "numClips = 23\n",
    "\n",
    "for i in range(numClips):\n",
    "    speakers.append(str(i+1))\n",
    "    \n",
    "print(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = keras.models.load_model('Trained Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(audio_Paths):\n",
    "    \n",
    "    data_X = []\n",
    "    \n",
    "    for path in audio_Paths:\n",
    "        \n",
    "        audioLength = librosa.get_duration(filename=path)\n",
    "        \n",
    "        if audioLength != 1.0:\n",
    "            continue\n",
    "        \n",
    "        audioFeatureArray = []        \n",
    "        y, sr = librosa.load(path)\n",
    "        \n",
    "        #mfcc\n",
    "        mfccArray = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        audioFeatureArray.append(mfccArray.flatten())\n",
    "        audioFeatureNumpyArray = np.array(audioFeatureArray)\n",
    "        \n",
    "        #zero_crossing_rate\n",
    "        zeroCrossingArray = librosa.feature.zero_crossing_rate(y=y)\n",
    "        np.append(audioFeatureNumpyArray, zeroCrossingArray.flatten())\n",
    "        \n",
    "        #spectral_rolloff\n",
    "        spectralRollOffArray = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        np.append(audioFeatureNumpyArray, spectralRollOffArray.flatten())\n",
    "        \n",
    "        data_X.append(audioFeatureNumpyArray.flatten())\n",
    "        \n",
    "    return data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllAudioFilePaths(speaker):\n",
    "    audioFilesPaths = [y for x in os.walk(\"Dataset/Youtube Speech Dataset/Dataset/{}\".format(speaker)) for y in glob(os.path.join(x[0], '*.wav'))]\n",
    "    return audioFilesPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For confusion matrix\n",
    "def runModel(speaker):\n",
    "   \n",
    "    audio_Paths = findAllAudioFilePaths(speaker)\n",
    "\n",
    "    audioFeatureArray = getFeatures(audio_Paths) \n",
    "            \n",
    "    validation_x = np.array(audioFeatureArray)\n",
    "\n",
    "    predictScore = model.predict(validation_x)        \n",
    "    classes = np.argmax(predictScore, axis = 1)\n",
    "\n",
    "    speakerCount = dict()\n",
    "    for classPredict in classes:\n",
    "        speakerCount[classPredict] = speakerCount.get(classPredict, 0) + 1\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"-------------------------\")\n",
    "    print(\"Testing model for {}\".format(speaker))\n",
    "    \n",
    "    for speaker in speakerCount: \n",
    "        print(\"Speaker: {} ----> Votes: {}\".format(speakers[int(speaker)], speakerCount[speaker] )) \n",
    "    print(\"-------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for speaker in speakers:\n",
    "#    runModel(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 4845, 880) for input Tensor(\"dense_input_2:0\", shape=(None, 4845, 880), dtype=float32), but it was called on an input with incompatible shape (None, 880).\n",
      "\n",
      "-------------------------\n",
      "Testing model for 1\n",
      "Speaker: 1 ----> Votes: 118\n",
      "Speaker: 19 ----> Votes: 1\n",
      "Speaker: 20 ----> Votes: 2\n",
      "Speaker: 22 ----> Votes: 1\n",
      "Speaker: 6 ----> Votes: 1\n",
      "Speaker: No Speaker ----> Votes: 1\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#runModel(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
