{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#audio feature extraction library\n",
    "import librosa\n",
    "from librosa import feature\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#model\n",
    "import tensorflow as tf\n",
    "from spela.spectrogram import Spectrogram \n",
    "from spela.melspectrogram import Melspectrogram\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllAudioFilePaths():\n",
    "    audioFilesPaths = [y for x in os.walk(\"Dataset/Youtube Speech Dataset/Dataset\") for y in glob(os.path.join(x[0], '*.wav'))]\n",
    "    return audioFilesPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = [\"Obama\", \"Hillary\", \"Ivanka\", \"Trump\", \"No Speaker\", \"Modi\", \"Xi-Jinping\", \"Chadwick-Boseman\"]\n",
    "\n",
    "def speakerToLabel(speakerName):\n",
    "    index = speakers.index(speakerName)\n",
    "    \n",
    "    if(index == -1):\n",
    "        print(\"Speaker not found: {}\".format(speakerName))\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakerAndAudio(audioPaths):\n",
    "    audio_Paths = []\n",
    "    labels = []\n",
    "    uniqueSpeakers = {}\n",
    "\n",
    "    for audioPath in audioPaths:\n",
    "        speakerName = audioPath.split(\"/\")[3]\n",
    "\n",
    "        audioLength = librosa.get_duration(filename=audioPath)\n",
    "        \n",
    "        if audioLength == 1.0:\n",
    "            audio_Paths.append(audioPath)\n",
    "            labels.append(speakerToLabel(speakerName))\n",
    "            uniqueSpeakers[speakerName] = uniqueSpeakers.get(speakerName, 0) + 1\n",
    "        else:\n",
    "            print(\"Audio clip discarded, actual length = {}\".format(audioLength))\n",
    "    \n",
    "    return audio_Paths, labels, uniqueSpeakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(audio_Paths):\n",
    "    \n",
    "    data_X = []\n",
    "    \n",
    "    for path in audio_Paths:\n",
    "        \n",
    "        audioFeatureArray = []        \n",
    "        y, sr = librosa.load(path)\n",
    "\n",
    "        #mfcc\n",
    "        mfccArray = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        \n",
    "        data_X.append(mfccArray.flatten())\n",
    "        \n",
    "\n",
    "    \n",
    "    return data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio clip discarded, actual length = 0.221\n",
      "Audio clip discarded, actual length = 0.4819954648526077\n",
      "Audio clip discarded, actual length = 0.66\n",
      "Audio clip discarded, actual length = 0.3\n",
      "Audio clip discarded, actual length = 0.6059863945578231\n",
      "Audio clip discarded, actual length = 0.12598639455782312\n",
      "Audio clip discarded, actual length = 0.7489795918367347\n",
      "Speakers: {'No Speaker': 579, 'Hillary': 3452, 'Ivanka': 1075, 'Xi-Jinping': 671, 'Modi': 1944, 'Chadwick-Boseman': 1625, 'Obama': 1168, 'Trump': 2496}\n",
      "Total Dataset size: 13010\n"
     ]
    }
   ],
   "source": [
    "audioPaths = findAllAudioFilePaths()\n",
    "audio_Paths, labels, uniqueSpeakers = getSpeakerAndAudio(audioPaths)\n",
    " \n",
    "    \n",
    "print(\"Speakers: {}\".format(uniqueSpeakers))\n",
    "print(\"Total Dataset size: {}\".format(len(audio_Paths)))\n",
    "\n",
    "\n",
    "data_X = getFeatures(audio_Paths)\n",
    "\n",
    "print(\"X data: {}\".format(len(data_X)))\n",
    "print(\"Y data: {}\".format(len(labels)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data_X, labels, test_size=0.2)\n",
    "\n",
    "train_x = np.array(train_X)\n",
    "train_y = np.array(train_Y)\n",
    "test_x = np.array(test_X)\n",
    "test_y = np.array(test_Y)\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "#from tf.keras.layers import Dense\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(12,input_shape= train_x.shape, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(len(speakers), activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4)\n",
    "            , loss = \"categorical_crossentropy\"\n",
    "            , metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_x, y=train_y, epochs=50, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
