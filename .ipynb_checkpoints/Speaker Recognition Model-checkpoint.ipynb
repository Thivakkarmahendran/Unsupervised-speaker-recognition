{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#audio feature extraction library\n",
    "import librosa\n",
    "from librosa import feature\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#model\n",
    "import tensorflow as tf\n",
    "from spela.spectrogram import Spectrogram \n",
    "from spela.melspectrogram import Melspectrogram\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllAudioFilePaths():\n",
    "    audioFilesPaths = [y for x in os.walk(\"Dataset/Youtube Speech Dataset/Dataset\") for y in glob(os.path.join(x[0], '*.wav'))]\n",
    "    return audioFilesPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = [\"Obama\", \"Hillary\", \"Ivanka\", \"Trump\", \"No Speaker\"]\n",
    "\n",
    "def speakerToLabel(speakerName):\n",
    "    index = speakers.index(speakerName)\n",
    "    \n",
    "    if(index == -1):\n",
    "        print(\"Speaker not found: {}\".format(speakerName))\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakerAndAudio(audioPaths):\n",
    "    audio_Paths = []\n",
    "    labels = []\n",
    "    uniqueSpeakers = {}\n",
    "\n",
    "    for audioPath in audioPaths:\n",
    "        speakerName = audioPath.split(\"/\")[3]\n",
    "\n",
    "        audioLength = librosa.get_duration(filename=audioPath)\n",
    "        \n",
    "        if audioLength == 1.0:\n",
    "            audio_Paths.append(audioPath)\n",
    "            labels.append(speakerToLabel(speakerName))\n",
    "            uniqueSpeakers[speakerName] = uniqueSpeakers.get(speakerName, 0) + 1\n",
    "        else:\n",
    "            print(\"Audio clip discarded, actual length = {}\".format(audioLength))\n",
    "    \n",
    "    return audio_Paths, labels, uniqueSpeakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(audio_Paths):\n",
    "    \n",
    "    data_X = []\n",
    "    \n",
    "    for path in audio_Paths:\n",
    "        \n",
    "        audioFeatureArray = []        \n",
    "        y, sr = librosa.load(path)\n",
    "\n",
    "        #mfcc\n",
    "        mfccArray = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        \n",
    "        data_X.append(mfccArray.flatten())\n",
    "        \n",
    "\n",
    "    \n",
    "    return data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio clip discarded, actual length = 0.221\n",
      "Audio clip discarded, actual length = 0.4819954648526077\n",
      "Audio clip discarded, actual length = 0.12598639455782312\n",
      "Audio clip discarded, actual length = 0.7489795918367347\n",
      "Speakers: {'No Speaker': 579, 'Hillary': 3452, 'Ivanka': 1075, 'Obama': 1168, 'Trump': 2496}\n",
      "Total Dataset size: 8770\n",
      "X data: 8770\n",
      "Y data: 8770\n"
     ]
    }
   ],
   "source": [
    "audioPaths = findAllAudioFilePaths()\n",
    "audio_Paths, labels, uniqueSpeakers = getSpeakerAndAudio(audioPaths)\n",
    " \n",
    "    \n",
    "print(\"Speakers: {}\".format(uniqueSpeakers))\n",
    "print(\"Total Dataset size: {}\".format(len(audio_Paths)))\n",
    "\n",
    "\n",
    "data_X = getFeatures(audio_Paths)\n",
    "\n",
    "print(\"X data: {}\".format(len(data_X)))\n",
    "print(\"Y data: {}\".format(len(labels)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data_X, labels, test_size=0.2)\n",
    "\n",
    "train_x = np.array(train_X)\n",
    "train_y = np.array(train_Y)\n",
    "test_x = np.array(test_X)\n",
    "test_y = np.array(test_Y)\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "#from tf.keras.layers import Dense\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(12,input_shape= train_x.shape, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(len(speakers), activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4)\n",
    "            , loss = \"categorical_crossentropy\"\n",
    "            , metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 7016, 12)          10572     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 7016, 8)           104       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 7016, 5)           45        \n",
      "=================================================================\n",
      "Total params: 10,721\n",
      "Trainable params: 10,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.7706 - accuracy: 0.6975 - val_loss: 0.7716 - val_accuracy: 0.6648\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.7034 - val_loss: 0.7454 - val_accuracy: 0.6494\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.6881 - val_loss: 0.6676 - val_accuracy: 0.7263\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.6820 - val_loss: 0.5335 - val_accuracy: 0.6990\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7255 - val_loss: 0.6544 - val_accuracy: 0.7491\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8120 - val_loss: 0.3492 - val_accuracy: 0.8255\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.8526 - val_loss: 0.2822 - val_accuracy: 0.8746\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.8880 - val_loss: 0.2191 - val_accuracy: 0.8900\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.8977 - val_loss: 0.2433 - val_accuracy: 0.8917\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9052 - val_loss: 0.2307 - val_accuracy: 0.8900\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9133 - val_loss: 0.1888 - val_accuracy: 0.9054\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9165 - val_loss: 0.1781 - val_accuracy: 0.9094\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9175 - val_loss: 0.1596 - val_accuracy: 0.9076\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9173 - val_loss: 0.1699 - val_accuracy: 0.9071\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9202 - val_loss: 0.1786 - val_accuracy: 0.9088\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9188 - val_loss: 0.1600 - val_accuracy: 0.9082\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9192 - val_loss: 0.1915 - val_accuracy: 0.9065\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9243 - val_loss: 0.1580 - val_accuracy: 0.9133\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9250 - val_loss: 0.1975 - val_accuracy: 0.9082\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9272 - val_loss: 0.1868 - val_accuracy: 0.9128\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9262 - val_loss: 0.1622 - val_accuracy: 0.9156\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9247 - val_loss: 0.1956 - val_accuracy: 0.9094\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9225 - val_loss: 0.1443 - val_accuracy: 0.9156\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9263 - val_loss: 0.2145 - val_accuracy: 0.9128\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9275 - val_loss: 0.1250 - val_accuracy: 0.9105\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9275 - val_loss: 0.1527 - val_accuracy: 0.9082\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9269 - val_loss: 0.1345 - val_accuracy: 0.9111\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9290 - val_loss: 0.1728 - val_accuracy: 0.9133\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9290 - val_loss: 0.1978 - val_accuracy: 0.9105\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0831 - accuracy: 0.9265 - val_loss: 0.1410 - val_accuracy: 0.9116\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9277 - val_loss: 0.1578 - val_accuracy: 0.9071\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9142 - val_loss: 0.2174 - val_accuracy: 0.9099\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9282 - val_loss: 0.1712 - val_accuracy: 0.9094\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9302 - val_loss: 0.1425 - val_accuracy: 0.9116\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9312 - val_loss: 0.1733 - val_accuracy: 0.9133\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9302 - val_loss: 0.1766 - val_accuracy: 0.9105\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9293 - val_loss: 0.1630 - val_accuracy: 0.9111\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9292 - val_loss: 0.2162 - val_accuracy: 0.9111\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9275 - val_loss: 0.1788 - val_accuracy: 0.9094\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9293 - val_loss: 0.2862 - val_accuracy: 0.9054\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9233 - val_loss: 0.1532 - val_accuracy: 0.9099\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9286 - val_loss: 0.2353 - val_accuracy: 0.9116\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9253 - val_loss: 0.1405 - val_accuracy: 0.9088\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9292 - val_loss: 0.2130 - val_accuracy: 0.9094\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9307 - val_loss: 0.1879 - val_accuracy: 0.9128\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9310 - val_loss: 0.1369 - val_accuracy: 0.9116\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9322 - val_loss: 0.1759 - val_accuracy: 0.9139\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9299 - val_loss: 0.1558 - val_accuracy: 0.9111\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9284 - val_loss: 0.1801 - val_accuracy: 0.9128\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9320 - val_loss: 0.1576 - val_accuracy: 0.9133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98e62a2f10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, y=train_y, epochs=50, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
