{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#audio feature extraction library\n",
    "import librosa\n",
    "from librosa import feature\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#model\n",
    "import tensorflow as tf\n",
    "from spela.spectrogram import Spectrogram \n",
    "from spela.melspectrogram import Melspectrogram\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllAudioFilePaths():\n",
    "    audioFilesPaths = [y for x in os.walk(\"Dataset/Youtube Speech Dataset/Dataset\") for y in glob(os.path.join(x[0], '*.wav'))]\n",
    "    return audioFilesPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speakerToLabel(speakerName):\n",
    "    if speakerName == \"Obama\":\n",
    "        return 0\n",
    "    elif speakerName == \"Hillary\":\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeakerAndAudio(audioPaths):\n",
    "    audio_Paths = []\n",
    "    labels = []\n",
    "    uniqueSpeakers = set()\n",
    "\n",
    "    for audioPath in audioPaths:\n",
    "        speakerName = audioPath.split(\"/\")[3]\n",
    "\n",
    "        audioLength = librosa.get_duration(filename=audioPath)\n",
    "        \n",
    "        if audioLength == 1.0:\n",
    "            audio_Paths.append(audioPath)\n",
    "            labels.append(speakerToLabel(speakerName))\n",
    "            uniqueSpeakers.add(speakerName)\n",
    "        else:\n",
    "            print(\"Audio less than 1 second, actual length = {}\".format(audioLength))\n",
    "    \n",
    "    return audio_Paths, labels, uniqueSpeakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(audio_Paths):\n",
    "    \n",
    "    data_X = []\n",
    "    \n",
    "    for path in audio_Paths:\n",
    "        \n",
    "        audioFeatureArray = []        \n",
    "        y, sr = librosa.load(path)\n",
    "\n",
    "        #mfcc\n",
    "        mfccArray = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        \n",
    "        data_X.append(mfccArray.flatten())\n",
    "        \n",
    "\n",
    "    \n",
    "    return data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio less than 1 second, actual length = 0.4819954648526077\n",
      "Audio less than 1 second, actual length = 0.12598639455782312\n",
      "Speakers: {'Obama', 'Hillary'}\n",
      "Total Dataset size: 4620\n",
      "X data: 4620\n",
      "Y data: 4620\n"
     ]
    }
   ],
   "source": [
    "audioPaths = findAllAudioFilePaths()\n",
    "\n",
    "audio_Paths, labels, uniqueSpeakers = getSpeakerAndAudio(audioPaths)\n",
    " \n",
    "print(\"Speakers: {}\".format(uniqueSpeakers))\n",
    "print(\"Total Dataset size: {}\".format(len(audio_Paths)))\n",
    "\n",
    "data_X = getFeatures(audio_Paths)\n",
    "\n",
    "print(\"X data: {}\".format(len(data_X)))\n",
    "print(\"Y data: {}\".format(len(labels)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3696, 880)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data_X, labels, test_size=0.2)\n",
    "\n",
    "train_x = np.array(train_X)\n",
    "train_y = np.array(train_Y)\n",
    "test_x = np.array(test_X)\n",
    "test_y = np.array(test_Y)\n",
    "\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "#from tf.keras.layers import Dense\n",
    "\n",
    "def create_model(speech_feature):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(12,input_shape= train_x.shape, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-4)\n",
    "            , loss = \"BinaryCrossentropy\"\n",
    "            , metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 3696, 12)          10572     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3696, 8)           104       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3696, 1)           9         \n",
      "=================================================================\n",
      "Total params: 10,685\n",
      "Trainable params: 10,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\"spectrogram\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 1.6113e-05 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba5e377350>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, y=train_y, epochs=1, validation_data=(test_x, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
